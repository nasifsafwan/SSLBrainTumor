{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b98d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588428c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "\n",
    "class BrainTumorDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths, self.labels = self.process_images(root_dir)\n",
    "        self.classes = ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.classes.index(self.labels[idx])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "    def process_images(self, path):\n",
    "        images = []\n",
    "        labels = []\n",
    "        for category in os.listdir(path):\n",
    "            category_path = os.path.join(path, category)\n",
    "            if os.path.isdir(category_path):\n",
    "                for img_name in os.listdir(category_path):\n",
    "                    img_path = os.path.join(category_path, img_name)\n",
    "                    if self.is_image_file(img_path):\n",
    "                        images.append(img_path)\n",
    "                        labels.append(category)\n",
    "        return images, labels\n",
    "\n",
    "    def is_image_file(self, filename):\n",
    "        valid_image_extensions = [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\"]\n",
    "        return any(filename.lower().endswith(ext) for ext in valid_image_extensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8f96ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Less aggressive cropping\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),  # Reduce rotation angle\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),  # Less aggressive color jitter\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7abc302",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BYOL(nn.Module):\n",
    "    def __init__(self, base_model, projection_size=256, projection_hidden_size=4096, momentum=0.996):\n",
    "        super(BYOL, self).__init__()\n",
    "        self.online_encoder = base_model\n",
    "        self.target_encoder = base_model\n",
    "        self.momentum = momentum\n",
    "\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(1000, projection_hidden_size),\n",
    "            nn.BatchNorm1d(projection_hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(projection_hidden_size, projection_size)\n",
    "        )\n",
    "        self.online_predictor = nn.Sequential(\n",
    "            nn.Linear(projection_size, projection_hidden_size),\n",
    "            nn.BatchNorm1d(projection_hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(projection_hidden_size, projection_size)\n",
    "        )\n",
    "\n",
    "        self._initialize_target_encoder()\n",
    "\n",
    "    def _initialize_target_encoder(self):\n",
    "        for param_q, param_k in zip(self.online_encoder.parameters(), self.target_encoder.parameters()):\n",
    "            param_k.data.copy_(param_q.data)\n",
    "            param_k.requires_grad = False \n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _momentum_update_target_encoder(self):\n",
    "        for param_q, param_k in zip(self.online_encoder.parameters(), self.target_encoder.parameters()):\n",
    "            param_k.data = param_k.data * self.momentum + param_q.data * (1 - self.momentum)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        online_proj_1 = self.projector(self.online_encoder(x1))\n",
    "        online_proj_2 = self.projector(self.online_encoder(x2))\n",
    "\n",
    "        online_pred_1 = self.online_predictor(online_proj_1)\n",
    "        online_pred_2 = self.online_predictor(online_proj_2)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self._momentum_update_target_encoder()\n",
    "\n",
    "            target_proj_1 = self.projector(self.target_encoder(x1))\n",
    "            target_proj_2 = self.projector(self.target_encoder(x2))\n",
    "\n",
    "        return online_pred_1, online_pred_2, target_proj_1, target_proj_2\n",
    "\n",
    "def byol_loss_fn(pred, target):\n",
    "    pred = nn.functional.normalize(pred, dim=-1)\n",
    "    target = nn.functional.normalize(target, dim=-1)\n",
    "    return 2 - 2 * (pred * target).sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3966f9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fine-tune the model\n",
    "def fine_tune_model(classifier_model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
    "    # Unfreeze all layers in the backbone model\n",
    "    for param in classifier_model.backbone.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    # Re-initialize optimizer to update all parameters\n",
    "    optimizer = optim.Adam(classifier_model.parameters(), lr=1e-4)\n",
    "\n",
    "    # Fine-tune the model\n",
    "    train_model(classifier_model, train_loader, val_loader, criterion, optimizer, num_epochs, device)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "\n",
    "byol_model = BYOL(base_model).to(device)\n",
    "byol_optimizer = optim.Adam(byol_model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "classifier_model = Classifier(base_model).to(device)\n",
    "\n",
    "for param in classifier_model.backbone.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "classifier_optimizer = optim.Adam(classifier_model.parameters(), lr=1e-3)\n",
    "fine_tune_model(classifier_model, train_loader, val_loader, criterion, classifier_optimizer, num_epochs=30, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835049ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
